{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from libtiff import TIFF\n",
    "from libtiff import TIFFfile, TIFFimage\n",
    "from scipy.misc import imresize\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read the images in numerical order\n",
    "import re\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of file names of actual Satellite images for traininig \n",
    "filelist_trainx = sorted(glob.glob('Inter-IIT-CSRE/The-Eye-in-the-Sky-dataset/sat/*.tif'), key=numericalSort)\n",
    "# List of file names of classified images for traininig \n",
    "filelist_trainy = sorted(glob.glob('Inter-IIT-CSRE/The-Eye-in-the-Sky-dataset/gt/*.tif'), key=numericalSort)\n",
    "\n",
    "# List of file names of actual Satellite images for testing \n",
    "filelist_testx = sorted(glob.glob('Inter-IIT-CSRE/The-Eye-in-the-Sky-test-data/sat_test/*.tif'), key=numericalSort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not useful, might change the alignment of 4 channels in sat images\n",
    "\n",
    "# Resizing the image to nearest dimensions multipls of 'stride'\n",
    "\n",
    "def resize(img, stride, n_h, n_w):\n",
    "    #h,l,_ = img.shape\n",
    "    ne_h = (n_h*stride) + stride\n",
    "    ne_w = (n_w*stride) + stride\n",
    "    \n",
    "    img_resized = imresize(img, (ne_h,ne_w))\n",
    "    return img_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding at the bottem and at the left of images to be able to crop them into 128*128 images for training\n",
    "\n",
    "def padding(img, w, h, c, crop_size, stride, n_h, n_w):\n",
    "    \n",
    "    w_extra = w - ((n_w-1)*stride)\n",
    "    w_toadd = crop_size - w_extra\n",
    "    \n",
    "    h_extra = h - ((n_h-1)*stride)\n",
    "    h_toadd = crop_size - h_extra\n",
    "    \n",
    "    img_pad = np.zeros(((h+h_toadd), (w+w_toadd), c))\n",
    "    #img_pad[:h, :w,:] = img\n",
    "    #img_pad = img_pad+img\n",
    "    img_pad = np.pad(img, [(0, h_toadd), (0, w_toadd), (0,0)], mode='constant')\n",
    "    \n",
    "    return img_pad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding pixels to make the image with shape in multiples of stride\n",
    "\n",
    "def add_pixals(img, h, w, c, n_h, n_w, crop_size, stride):\n",
    "    \n",
    "    w_extra = w - ((n_w-1)*stride)\n",
    "    w_toadd = crop_size - w_extra\n",
    "    \n",
    "    h_extra = h - ((n_h-1)*stride)\n",
    "    h_toadd = crop_size - h_extra\n",
    "    \n",
    "    img_add = np.zeros(((h+h_toadd), (w+w_toadd), c))\n",
    "    \n",
    "    # Adding pixals of img into img_add as it is\n",
    "    img_add[:h, :w,:] = img\n",
    "    # Adding top few pixals of img to the bottom of img_add\n",
    "    img_add[h:, :w,:] = img[:h_toadd,:, :]\n",
    "    # Adding left few pixals of img to the right of img_add\n",
    "    img_add[:h,w:,:] = img[:,:w_toadd,:]\n",
    "    # In the remaining space adding some random pixals from the img to fill img_add\n",
    "    img_add[h:,w:,:] = img[h-h_toadd:h,w-w_toadd:w,:]\n",
    "    \n",
    "    return img_add    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing the image into crop_size*crop_size crops with a stride of crop_size/2 and makking list out of them\n",
    "\n",
    "def crops(a, crop_size = 128):\n",
    "    \n",
    "    stride = int(crop_size/2)\n",
    "    \n",
    "    croped_images = []\n",
    "    h, w, c = a.shape\n",
    "    \n",
    "    n_h = int(int(h/stride))\n",
    "    n_w = int(int(w/stride))\n",
    "    \n",
    "    # Padding using the padding function we wrote\n",
    "    a = padding(a, w, h, c, crop_size, stride, n_h, n_w)\n",
    "    \n",
    "    # Resizing as required\n",
    "    ##a = resize(a, stride, n_h, n_w)\n",
    "    \n",
    "    # Adding pixals as required\n",
    "    ##a = add_pixals(a, h, w, c, n_h, n_w, crop_size, stride)\n",
    "    \n",
    "    # Slicing the image into 128*128 crops with a stride of 64\n",
    "    for i in range(n_h-1):\n",
    "        for j in range(n_w-1):\n",
    "            crop_x = a[(i*stride):((i*stride)+crop_size), (j*stride):((j*stride)+crop_size), :]\n",
    "            croped_images.append(crop_x)\n",
    "    return croped_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading, padding, cropping and making array of all the cropped images of all the trainig sat images\n",
    "trainx_list = []\n",
    "\n",
    "for fname in filelist_trainx:\n",
    "    \n",
    "    # Reading the image\n",
    "    tif = TIFF.open(fname)\n",
    "    image = tif.read_image()\n",
    "    \n",
    "    # Padding as required and cropping\n",
    "    crops_list = crops(image)\n",
    "    #print(len(crops_list))\n",
    "    trainx_list = trainx_list + crops_list\n",
    "    \n",
    "# Array of all the cropped Training sat Images    \n",
    "trainx = np.asarray(trainx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading, padding, cropping and making array of all the cropped images of all the trainig gt images\n",
    "trainy_list = []\n",
    "\n",
    "for fname in filelist_trainy:\n",
    "    \n",
    "    # Reading the image\n",
    "    tif = TIFF.open(fname)\n",
    "    image = tif.read_image()\n",
    "    \n",
    "    # Padding as required and cropping\n",
    "    crops_list = crops(image)\n",
    "    \n",
    "    trainy_list = trainy_list + crops_list\n",
    "    \n",
    "# Array of all the cropped Training gt Images    \n",
    "trainy = np.asarray(trainy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading, padding, cropping and making array of all the cropped images of all the testing sat images\n",
    "testx_list = []\n",
    "\n",
    "for fname in filelist_testx:\n",
    "    \n",
    "    # Reading the image\n",
    "    tif = TIFF.open(fname)\n",
    "    image = tif.read_image()\n",
    "    \n",
    "    # Padding as required and cropping\n",
    "    crops_list = crops(image)\n",
    "    \n",
    "    testx_list = testx_list + crops_list\n",
    "    \n",
    "# Array of all the cropped Testing sat Images  \n",
    "testx = np.asarray(testx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3726, 128, 128, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(input_size = (128,128,4)):\n",
    "    \n",
    "    # Left side of the U-Net\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    \n",
    "    # Bottom of the U-Net\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    \n",
    "    # Upsampling Starts, right side of the U-Net\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(conv9)\n",
    "    conv9 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "\n",
    "    # Output layer of the U-Net with a softmax activation\n",
    "    conv10 = Conv2D(3, 1, activation = 'softmax')(conv9)\n",
    "\n",
    "    model = Model(input = inputs, output = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 0.00001), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet()\n",
    "\n",
    "hist = model.fit(trainx, trainy, epochs= 20, batch_size= 16,validation_split=0.06, verbose=1)\n",
    "\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation (Do not run these right now, need to debug and verify)\n",
    "\n",
    "datagen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Do not run this right now)\n",
    "\n",
    "x_datagen = ImageDataGenerator(**datagen_args)\n",
    "y_datagen = ImageDataGenerator(**datagen_args)\n",
    "\n",
    "seed = 1\n",
    "\n",
    "x_datagen.fit(trainx, augment=True, seed = seed)\n",
    "y_datagen.fit(trainy, augment=True, seed = seed)\n",
    "\n",
    "x_generator = x_datagen.flow(trainx, seed=seed)\n",
    "\n",
    "y_generator = y_datagen.flow(trainy, seed=seed)\n",
    "\n",
    "train_generator = zip(x_generator, y_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with Augmentation (Do not run this right now)\n",
    "model.fit_generator(train_generator, epochs = 20, steps_per_epoch=405)\n",
    "model.save(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
